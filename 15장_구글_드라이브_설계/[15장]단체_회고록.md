# 🧾 대규모 시스템 설계 스터디 회고록 – 15장

**일시:** 2025년 7월 30일 (수) 오후 9시 ~ 10시 30분

**참여자:** 박이현, 박용훈, 전희진

---

## ✅ 질문 중심 회고 요약

### 🧑‍💻 전희진

**💬 질문 1**

> 변경된 파일을 감지할 때 주어진 파일을 작은 블록들로 분할하고 거기서 hash 값을 비교해 변경이 있는 블록들만 교체하는 것으로 이해를 했는데요. hash 값이라는 것은 최초에 블록마다 존재하지 않았을 것 같은데, 어떻게 블록 별로 변경된 것을 감지할 수 있는 건가요?

* **해시 기반 변경 감지의 원리**:
  * 동일한 데이터는 언제든지 같은 해시 값을 생성 (해시 함수의 특성)
  * 블록 단위로 해시 값을 계산하여 이전 버전과 비교
  * **변경되지 않은 블록**: 이전과 동일한 해시 값 유지
  * **변경된 블록**: 다른 해시 값을 가지므로 변경 감지 가능

* **파일 유형별 처리 방식의 의문**:
  * **텍스트 파일**: 블록 분할이 상대적으로 명확
  * **이미지 파일**: 구역별 분할이 가능한지 의문
    * 예: 이미지에 스티커 하나 추가 시 어떤 블록이 변경된 것으로 감지할 것인가?
  * **이미지/동영상**: 파일 크기에 따라 블록 분할 여부 결정될 수 있음
    * 작은 파일: 전체 파일을 하나의 블록으로 처리
    * 큰 파일: 적절한 크기로 블록 분할

* **기술적 한계**: 파일 형식에 따른 최적화된 변경 감지 방식이 다를 수 있음

---

### 🧑‍💻 박용훈

**💬 질문 1**

> 구글 드라이브 설계는 다른 장들과 달리 동시성 이슈가 부각되는 장이었던 것 같습니다. 하지만 다른 장들은 대용량 트래픽 발생을 시켜 그것에 대한 문제점을 해결하는 것에 초점을 맞췄지만 이번 장은 그런 느낌은 전혀 들지 않더라구요. 그래서 이번 장에서 말하는 대용량 트래픽은 어떤 것일까요?

* **15장의 차별화된 특성**:
  * 다른 장들과 다른 성격의 시스템 설계
  * **동시성 이슈**가 가장 부각되는 장
  * 단순한 요청 수 증가가 아닌 **다른 종류의 대용량 처리**

* **구글 드라이브의 대용량 트래픽 정의**:
  * **요청 수가 아닌 다른 차원의 트래픽**:
    1. **파일 단위의 데이터 크기** - 개별 파일의 용량
    2. **누적 변경 내역 처리** - 버전 관리 및 동기화
    3. **복잡한 동기화 및 충돌 해결 로직** - 여러 클라이언트 간 동시 수정

* **핵심 기술적 도전 과제**:
  * **I/O 병목**: 대용량 파일 읽기/쓰기 처리
  * **데이터 정합성**: 동시 접근 시 데이터 일관성 유지
  * **실시간 반영**: 변경사항의 즉시 동기화
  * **동시성 제어**: 동시 편집 시 충돌 방지 및 해결
  * **분산 파일 시스템**: 대용량 저장소 관리
  * **충돌 감지**: 동시 수정 감지 및 병합

* **트래픽 특성의 차이**:
  * 일반적인 웹 서비스: 다수의 작은 HTTP 요청 처리
  * 구글 드라이브: 소수의 대용량 파일 및 복잡한 동기화 로직 처리

---

### 🧑‍💻 박이현

**💬 질문 1**

> 허가받은 사용자만이 올바른 장소에 비디오를 업로드할 수 있도록 하기 위해, 미리 사인된(pre-signed) 업로드 URL을 이용한다고 하는데요. 이 부분이 정확히 어떤 프로세스로 이루어지는지 궁금합니다.

* **Pre-signed URL의 개념**: AWS S3에서 제공하는 보안 기능
* **동작 프로세스**:
  1. **사용자 인증**: 애플리케이션 레벨에서 사용자 인증 및 권한 확인
  2. **URL 생성**: 인증된 사용자에 대해 서버가 특별한 업로드 URL 생성
  3. **메타데이터 포함**: URL에 권한 정보, 유효 기간 등을 포함
  4. **제한된 접근**: 해당 URL을 아는 사용자만 특정 위치에 파일 업로드 가능

* **보안 메커니즘**:
  * **시간 제한**: URL에 유효 기간 설정 가능
  * **권한 범위**: 특정 경로에만 업로드 허용
  * **사용자 특정**: 인증된 특정 사용자만 사용 가능

* **실무 적용 사례**:
  * 줌의 영상 공유 링크와 유사한 개념
  * 임시적이고 제한적인 접근 권한 부여

* **S3 의존성**: AWS S3의 고유 기능으로, 자체 시스템 구축 시에는 별도 로직 개발 필요

---

## 📝 회고 및 개선 제안

* **학습의 한계점**: 14-15장은 실제 개발 경험 없이는 깊이 있는 이해가 어려운 영역
* **실무 경험 부족**: AWS S3, 분산 파일 시스템 등에 대한 실무 경험 부족으로 추상적 이해에 그침
* **스터디의 가치**: 1-13장까지는 실질적인 도움이 되었으나, 후반부는 개념적 학습 수준
* **완주의 의미**: 8명으로 시작하여 5명이 끝까지 완주 (62.5% 완주율)

---

## 🔍 보완 학습 제안

* **분산 파일 시스템 실습**:
  * HDFS, GFS 등 분산 파일 시스템 아키텍처 학습
  * 파일 청킹, 복제, 일관성 메커니즘 실습
* **AWS S3 실무 활용**:
  * Pre-signed URL 생성 및 활용 실습
  * S3 버킷 정책, IAM 권한 관리
  * 대용량 파일 업로드 최적화 (멀티파트 업로드)
* **동시성 제어 심화**:
  * 분산 락(Distributed Lock) 구현
  * Conflict Resolution 알고리즘 (예: Operational Transform)
  * CRDT(Conflict-free Replicated Data Types) 학습
* **버전 관리 시스템**:
  * Git의 내부 동작 원리 분석
  * 델타 압축, 해시 기반 변경 감지 실습
* **실시간 협업 도구 구현**:
  * Google Docs 스타일의 실시간 공동 편집 시스템
  * WebSocket 기반 실시간 동기화
* **대용량 파일 처리**:
  * 스트리밍 업로드/다운로드 구현
  * 청크 기반 파일 분할 및 병합
  * 중복 제거(Deduplication) 알고리즘