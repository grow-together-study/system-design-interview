
# 🧾 대규모 시스템 설계 스터디 회고록 – 2장

**일시:** 2025년 6월 18일 (수) 오후 9시 ~ 10시 20분

**참여자:** 박이현, 박용훈, 김호섭, 최선강 

---

## ✅ 전체 흐름 요약
### 1. 디스크 I/O 병목에 대한 대응 방안
- **문제 인식**: "디스크 탐색은 피하라"는 시스템 설계 원칙에 따라, 디스크 I/O는 병목의 주요 원인 중 하나.

- **해결 전략**:
    - 인메모리 캐시 활용 (Redis, Caffeine 등)
    - 읽기/쓰기 분리 (CQRS)
    - 메시지 큐 기반 비동기 처리 (Kafka 등)
    - 쿼리 튜닝 및 최적화
    - DB 샤딩 혹은 파티셔닝

- **회고 포인트**:
    - 실제 캐시 적용 경험이 적어도, "읽기 비율이 높은 API"를 기준으로 캐시 우선순위를 정하는 전략에 대한 논의가 활발히 이루어짐
    - CQRS와 레플리케이션의 차이에 대한 인식 공유
    - 로우레벨 I/O 병렬화는 현실적인 선택지로 고려되기 어려움

---

## 💡 주요 질문 & 요약 답변

* **디스크 병목이 발생하면 어떻게 대응할 수 있을까?**
  → 캐시/비동기화/샤딩/파티셔닝/쿼리 최적화 등 단계별 대응

* **메모리 캐시만으로 모든 문제를 해결할 수 있을까?**
  → TTL, eviction 정책 이해와 캐시 무효화 전략이 병행되어야 함

* **읽기 성능 개선을 위해 CQRS 또는 레플리카 DB는 언제 쓰는가?**
  → 정합성이 절대적인 서비스는 레플리카보다는 트랜잭션 분리가 선행됨

---

## 📝 회고 및 개선 제안

* 실무 경험 부족해도 API 특성(읽기 중심 vs 쓰기 중심)만 파악해도 전략 수립 가능
* 캐시 hit/miss 비율에 따른 효과 추정 연습도 병행해보기
* 디스크 병목을 단순 저장 장치 문제로만 보지 않고 **애플리케이션 구조 문제**로 해석하는 훈련 필요

---

## 🔍 보완 학습 제안

* Redis 기반 캐시 구조 실습
* CQRS 구현 예제(Spring 기준)
* 샤딩 구조 설계 및 파티션 키 설정 기준 비교
* Kafka, Redis Streams 활용한 비동기 처리 흐름 실습

<br>

# 🧾 대규모 시스템 설계 스터디 회고록 – 3장

---

## ✅ 전체 흐름 요약
#### 2. 대량 알림 발송 후 유입 트래픽 대응 전략
- **문제 상황**: 푸시 알림 혹은 이벤트 메시지를 대량 발송 시, 수십만 사용자의 동시 접속으로 인한 시스템 부하 발생

- **대응 전략**:
    - 발송 측면: 점진적/배치 발송, 유휴 시간대 발송
    - 유입 측면:
        - CDN 활용 (정적 페이지)
        - 읽기 요청 캐시 처리
        - 레이트 리밋, 쓰로틀링
        - 메시지 큐 기반 요청 큐잉
        - Auto-scaling + Load Balancer 적용
        - 대기열 UI 적용 (예: "당신은 대기순번 115번입니다")

- **회고 포인트**:
    - 실무 경험에 기반한 스케일아웃 우선 전략 공감
    - CDN 사용 조건(정적 리소스)에 대한 개념 공유
    - APM 없이 병목 지점을 판단하는 것의 한계 지적

#### 3. 좋아요 시스템 설계

- **문제 상황**: 대규모 유저가 동시에 특정 게시물에 좋아요를 누를 경우, DB 부하 및 일관성 문제 발생 가능

- **설계 방향**:

    - Redis set으로 유저-게시글 중복 체크 및 카운팅

    - 메시지 큐를 통한 DB 쓰기 요청 비동기화

    - RDB에는 일정 주기 동기화

    - 좋아요 수는 Redis 캐시로 빠르게 응답

    - 조회 시 캐시 우선 조회

- **회고 포인트**:

    - JPA 대신 JPQL/Native Query 사용하여 성능 확보 필요성 인식

    - 비정규화를 통한 조회 속도 개선 사례 공유 (ex. 카카오 오픈채팅 좋아요)


#### 4. Redis는 왜 싱글스레드인데도 빠른가?

- **질문 제기**: 싱글스레드 구조인데 어떻게 높은 처리량을 달성하는가?

- **답변 요약**:

    - Redis는 **비동기 이벤트 루프 + 논블로킹 I/O** 기반

    - 멀티스레딩에서 발생하는 컨텍스트 스위칭 비용이 없음

    - 순차적 요청 처리 방식이 오히려 고속 처리에 유리한 구조

- **회고 포인트**:

    - 운영체제 관점에서의 컨텍스트 스위칭 개념과 연결 필요

    - Redis 설계 원리에 대한 더 깊은 이해 필요 (이벤트 루프 작동 방식 등)


#### 5. Kafka 브로커 구성과 메시지 처리량 튜닝

- **질문 시나리오**:

    - 메시지 크기: 평균 1MB

    - 브로커 메모리: 1GB

    - 초당 메시지 발행량: 10,000건 (총 10GB)

    - 컨슈머 처리량: 초당 1,000건

- **주요 논의 내용**:

    - 이 구성은 단일 브로커, 1GB 메모리 환경에서는 현실적으로 불가능

    - 기본적으로 Kafka는 최소 3대 이상의 브로커 클러스터 구성이 필수

    - 브로커 메모리를 올리는 것이 우선적인 조치이며, 이후에 파티셔닝, 컨슈머 스케일아웃 등의 튜닝을 적용해야 함

    - 메시지를 청크 단위로 쪼개는 방식, 발행 주기 지연 등도 추가 고려 대상

    - 컨슈머가 Spark, Flink 등 외부 프레임워크인 경우 처리 흐름이 다를 수 있다는 점 인식

    - Kafka의 메시지는 소비 이후에도 브로커 내에 보존되며, 만료 주기 설정을 통해 삭제됨

- **회고 포인트**:

    - Kafka의 기본 구성(브로커 수, 리플리케이션 구조 등)에 대한 이해 필요

    - 컨슈머와 브로커의 독립성을 이해하고, 리소스 병목 포인트를 분리해서 바라보는 훈련이 필요함

    - 단순히 throughput을 높이는 것이 아니라, 전체 파이프라인 구조를 기반으로 한 아키텍처 설계가 중요
---

## 💡 주요 질문 & 요약 답변

* **대량 알림 발송 후 트래픽을 안정적으로 처리하려면?**
  → 발송 분산, 접속 분산, 트래픽 제어, Auto Scaling, 메시지 큐 조합 활용

* **좋아요 수를 정확하고 빠르게 처리하려면?**
  → Redis 중복 체크 + MQ 비동기 쓰기 + 캐시 중심 조회 설계

* **Redis는 왜 싱글스레드인데도 고성능인가?**
  → Non-blocking I/O + 컨텍스트 스위칭 없음 + 이벤트 루프 기반 처리

* **Kafka 처리량이 브로커 스펙을 초과하면?**
  → 메모리 확장, 브로커 다중 구성, 파티셔닝, 컨슈머 확장, 메시지 청크화 등 고려

---

## 📝 회고 및 개선 제안

* Redis, Kafka 등 개념적 이해에서 벗어나 실제 처리 흐름을 단계적으로 정리하는 훈련 필요
* 캐시, 메시지 큐, 대기열, 대용량 처리 분산 전략의 상호작용 이해 강화 필요
* 스터디 참가자 간 경험 차이를 보완하기 위해 실습 기반 사례 공유 강화 예정

---

## 🔍 보완 학습 제안

* 좋아요 수 Redis 처리 실습: 중복 방지 + 집계 + 주기적 동기화
* Kafka 기본 구조 실습: 브로커 구성, 파티션, 리텐션 설정
* Redis 이벤트 루프 내부 구조 분석
* Auto Scaling 정책 설계 실습 (CloudWatch, GCP metrics 기반 등)
